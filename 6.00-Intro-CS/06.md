## Approximate Solutions for Finding Root

If we were to find the solution for the root of any non-negative integer, we
could try to find a solution that is close enough to actual solution.

We could start with exhaustive enumeration - take small steps to generate
guesses in order and check to see whether it is close enough.

To do so, we need to define how good is "good enough"?

Let's start with a guess and increment by some small value.

```
(|guess^3| - cube) <= epsilon

where epsilon is sufficiently small
```

Hence, we can make following observations:

- By decreasing the increment size for next step, program will run slow as it
  will go through more numbers.

- By increasing the epsilon, our answer will become more and more inaccurate
  but will speed up the program as we can find good enough solution faster.

```python
target = 27
epsilon = 0.01
guess = 0.0
increment = 0.0001
count = 0

while abs(guess**3 - target) >= epilson:
    guess += increment
    count += 1

print(f"Program has taken {count} steps")

if abs(guess**3 - target) >= epsilon:
    print(f"Cannot find cube root of {target})
else:
    print(f"{guess} is closest to the cube root of {target}")
```

Above example will have taken 29997 steps inorder to find the close enough
solution to the cube root of 27 - which gives result of 2.999700000.

Note that if we increment is sufficiently large, we can go past the check in
while loop and never escape - entering infinite loop - hence, we would also add
in the additional check in the while loop where we check whether `guess <=
cube`.

This approach appears to be inefficient - let's improve upon this.

## Bisection Search

We know that finding a square root is essentially finding a number on line
problem - there is a square root exist between the number 1 and x.

Hence, rather than exhaustively trying things starting at 1, suppose that we
start by picking the number in the middle in this range. This guess can be
better.

But maybe the guess was not close - was it too big or too small? If we can see
that `g**2 > x`, then g has to be too big - so we have to reduce the search
space on the lower half where range is now (1, g].

So, we are effectively discarding half of our search space at each iteration
whenever we fail to find the guess that is not close enough.

```python
x = 25
epsilon = 0.01
count = 0
lo, hi = 1.0, x
guess = lo + (hi - lo) / 2.0

while abs(guess**2 - x) >= epsilon:
    if guess**2 < x:
        lo = guess
    else:
        hi = guess
    guess = lo + (hi - lo) / 2.0
    count += 1

print(f'It has taken {count} number of steps')
print(f'{guess} is close to square root of {x}')
```

## Convergence

Reducing the search space is as follows:

- First step reduces by N/2
- Second step reduces by N/4
- K step reduces by N/2^K

Hence, the guess converges on the order of log(N) number of steps.

Bisection can only work when value of function varies monotonically with input.

Suppose we want to modify to find the root for negative integers. For x < 1,
search space would be from x to 1.


